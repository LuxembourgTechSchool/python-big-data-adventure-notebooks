{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Data - Crash Course Notebook\n",
    "\n",
    "**Welcome in this notebook!**\n",
    "\n",
    "Here, you will do your **first steps** in the world of Big Data.\n",
    "And as a start, we will take a look at data from [IMDB Movie Dataset](https://www.kaggle.com/deepmatrix/imdb-5000-movie-dataset).\n",
    "\n",
    "This notebook will guide you trough all the steps required to perform some interesting analysis and exploration of a large dataset.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing Libraries\n",
    "\n",
    "Before we start writing code, we need to import a few libraries that will give us access to some awesome tools.\n",
    "More precisely, we will load:\n",
    "\n",
    "- **pandas** for loading large data sets into memory and working with it efficiently\n",
    "- **numpy** for doing all kinds of scientific computations (matrices, vectors, ...)\n",
    "- **matplotlib** for creating beautiful plots and graphs right into this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Panda and give it a shorter name \"pd\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import numpy and give it a shorter name \"np\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import pyplot from malplotlib and give it a shorter name \"plt\".\n",
    "\n",
    "\n",
    "# Tell Jupyter to to print plots in the cell results (Specific to notebooks only)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2. Loading Data\n",
    "\n",
    "All right. Now we have our libraries ready to go.\n",
    "\n",
    "Next we are going to load the data that you have downloaded.\n",
    "This data should be in the same folder as this notebook under `../data/movie_data/`.\n",
    "\n",
    "The data is in a CSV file. To load it, we can use a function called `read_csv` in pandas. (Just google [\"pandas load csv\"](https://www.google.com/search?q=pandas+load+csv) and you will find the answer.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the CSV file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good.\n",
    "\n",
    "Now, let's take a look a the data and see if something has been loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, this is quite a lot of data. How about we just pring the first few?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print the first 5 lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print the first 10 lines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is really good at handling big datasets in memory.\n",
    "It's more powerful than standard Python arrays.\n",
    "\n",
    "Let's take a look at the type of our variable `movie_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('The type of movie_data is:', ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we are working with a `DataFrame` in this case.\n",
    "\n",
    "This is important to know, because now you can search specifically on Google using the keyword \"pandas DataFrame\" and find very relevant knowledge (e.g. the [official documentation](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)).\n",
    "\n",
    "Note that there exists other types of data structures in pandas.\n",
    "When working with pandas and numpy, it is very important that you keep track (in your mind at least) of what is the type of each variable, because each library has its own functions and everything is not always compatible with each other. So, for now, just remember to keep an eye on what data structures you are working with!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Going back with the example of a pandas DataFrame, we can also access the rows with the normal square brackets syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print the first 10 lines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Explore the Data\n",
    "\n",
    "- Import libraries - **OK**\n",
    "- Load dataset - **OK**\n",
    "- Take a look at the data - **OK**\n",
    "\n",
    "Next, we will look with more detail at what we really have and what is the meaning of the data.\n",
    "\n",
    "First, let's check how big our dataset is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Option 1\n",
    "print('Movie Dataset has {} rows'.format( ... ))\n",
    "\n",
    "# Option 2\n",
    "print('Movie Dataset has {} rows'.format( ... ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting. The `shape` gives us a [tuple](https://www.tutorialspoint.com/python/python_tuples.htm) in the form of (number_of_rows, number_of_columns).\n",
    "\n",
    "Pandas DataFrames also have an attribute `size`. Let's check that out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Size of the DataFrame is {}'.format( ... ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What? Yep, looking at the [documenation](http://pandas.pydata.org/pandas-docs/version/0.18.1/generated/pandas.DataFrame.size.html) we can read that `size` is the number of elements. Each cell is an element. If we compute `#rows x #columns` we should get the same value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The first element of shape is the #rows and the second is the #columns\n",
    "print('Size of the DataFrame is {}'.format( ... ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so we have about 5000 rows.\n",
    "\n",
    "The next thing we will look at is the columns. And to print the values of the columns we can of course just print part of the data or we can access the columns attribute like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movie_data_columns = ...\n",
    "print('The {} columns are:\\n'.format( ... ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we can now take only few more interesting columns for review the values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few subtle, yet important, things are going on here. To understand the code above we will take a look at the value and type of the variable at each step.\n",
    "\n",
    "To make things short, `movie_data.columns.values` gives us an `numpy.ndarray` and by [googling \"ndarray to list\"](https://www.google.com/search?q=ndarray+to+list) we directly find the answer, namely, there is a function `tolist()` that allows us to get a normal Python list.\n",
    "\n",
    "*Below are the steps:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('1. Type of movie_data                          :', type(movie_data))\n",
    "print()\n",
    "print('2. Value of movie_data.columns                 :', movie_data.columns)\n",
    "print('3. Type of movie_data.columns                  :', type(movie_data.columns))\n",
    "print()\n",
    "print('4. Value of movie_data.columns.values          :', movie_data.columns.values)\n",
    "print('5. Type of movie_data.columns.values           :', type(movie_data.columns.values))\n",
    "print()\n",
    "print('6. Value of movie_data.columns.values.tolist() :', movie_data.columns.values.tolist())\n",
    "print('7. Type of movie_data.columns.values.tolist()  :', type(movie_data.columns.values.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Back to our data:**\n",
    "\n",
    "The datasets contains 28 columns. That is already very interesting.\n",
    "\n",
    "We have basic informations like the title, country, budget, name of director and duration. We also have information about the 1., 2. and 3. actors (Name and Facebook likes). Then there are also some columns about the genre of the movie, the score and rating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Looking at the movie title\n",
    "\n",
    "We know that the column 'movie_title' is the title the movie. That's easy.\n",
    "\n",
    "To print only 1 column, we can use square brackets with the name of the column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('The type of a DataFrame column is:', ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so a columns a [pandas Series](http://pandas.pydata.org/pandas-docs/version/0.18.1/generated/pandas.Series.html). Looking at the documenation we can do several things:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Looking at the country\n",
    "\n",
    "Now, let's take a look at the country the movie comes from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems that there is already a lot from the USA. To be sure, let's print the number of unique countries and how many times they are represented:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Looking at the genres\n",
    "\n",
    "Here, we will take a look at the genres of the movies. This time we will only print 2 columns, the title and the genres. To do that we use the double square brackets in pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print the first 10 rows. Only print 2 columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All right, it seems that the genres is a string where all elements are spaced by a `|`(pipe) symbol. Keep this in mind, because this means that we will need to process this column if we want to work with it.\n",
    "\n",
    "Before we move on, let's get all movies where the genres contains the string \"Comedy\". With pandas, we can use the query notation `YOUR_DATA['COLUMN_NAME'].str.contains('YOUR_STRING')`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print all movies where genres contains the string \"Comedy\"\n",
    "# Only prints a few selected columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Looking at Actors and Directors\n",
    "\n",
    "We have also a lot of information about actors, directors and something about facebook likes, so let's just look at that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'director_name', \n",
    "    'director_facebook_likes',\n",
    "    'actor_1_name',\n",
    "    'actor_1_facebook_likes', \n",
    "    'actor_2_name',\n",
    "    'actor_2_facebook_likes', \n",
    "    'actor_3_name',\n",
    "    'actor_3_facebook_likes', \n",
    "    'cast_total_facebook_likes', \n",
    "]\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good. We could imagine to later plot this data and we might try to find out who has the most likes and the differences between 1., 2. and 3. actors. For the `director_facebook_likes`, we see that many values are 0. This means that it would require some cleaning, because many values are missing or do not exist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is probably enough for this initial exploration. Feel free now to explore, for example, the budget or even the ratings and imdb scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your Exploration code goes here...\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One last thing we need to try is the `info()` function on a DataFrame. This function returns the general information about the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get general information about the data\n",
    "# How many columns it has\n",
    "# Names of the columns\n",
    "# Types of the columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Great.** We have now some better understanding of what we are dealing with. We can feel confident enough to move on to the next step, which is pre-processing the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pre-Processing\n",
    "\n",
    "Now, it's time to manipulate our data so that it is easier to work with. Depending on your data, pre-processing can be very simple or very difficult or not even worth it.\n",
    "\n",
    "Looking at the video about pre-processing we know that there are a few simple things that we need to check.\n",
    "\n",
    "1. Are there any null / empty values in the dataset?\n",
    "1. Are there any duplicates? What does it mean?\n",
    "\n",
    "We know that the columns `genres`is not very nicely formatted for us. So we will split those values into individual columns, later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Empty / Null Values\n",
    "\n",
    "Let's first check if there are any empty elements in our dataset. This can give us a good hint of **how clean** our data is.\n",
    "\n",
    "As always, Google is your friend. Pandas has a really good website where many things are explained. In our case, this [awesome link](http://pandas.pydata.org/pandas-docs/stable/missing_data.html) might help you a loooot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# isnull() return a boolean same-sized object indicating if the values are null.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In pandas there is a [function](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.any.html) called `any()`, which return whether any element is True over a requested axis.\n",
    "\n",
    "So we can call this function on our previous object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# \"Are there any null values in the columns\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we see that each the columns that are marked `True` have one or more null values inside. So, for some movies, the language or country might not be defined. However, we also see that all movies have at least a title and a genre. So, that is great. Since, this is what is also interesting for us, we will probably not remove any datapoints.\n",
    "\n",
    "The previous cell returned a pandas Series. If we call again `any()` on it, we will apply the same logic again. This is really powerful. There are many solutions for each problem in Python. Here we used one way, but there are many more as you can see [here](http://stackoverflow.com/questions/29530232/python-pandas-check-if-any-value-is-nan-in-dataframe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# \"Are there any null values among the null values of the columns\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume that we want to remove all rows containing null / nan values, we could simply use the `dropna()` method. ([Documentation](http://pandas.pydata.org/pandas-docs/version/0.18.1/generated/pandas.DataFrame.dropna.html#pandas.DataFrame.dropna))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Size before dropna() :', ...)\n",
    "print('Size after dropna()  :', ...)\n",
    "\n",
    "# Note that dropna() return a new object. So to use the result you should do: mydata = mydata.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As said before, we are not going to remove a row when one columns does not have a null value in this example.\n",
    "\n",
    "However, let's say that we want to later work on the gross and 1. actor data. We can and should now clean and remove all rows where those values are not defined. And if for example the 2. actor is not defined, we can ignore it for now.\n",
    "\n",
    "In pandas, the `dropna()` function can be given a subset, where you define the columns to check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print('Size if dropna() is performed: ', ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks kind of reasonable, so let's do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Duplicates\n",
    "\n",
    "Now, let's handle duplicates. And for that, we will start like before, by finding out how many duplicate rows there are.\n",
    "\n",
    "Guess what? [There is a function for that](http://pandas.pydata.org/pandas-docs/version/0.17.1/generated/pandas.DataFrame.duplicated.html). Pandas is just amazing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# By default, all duplicates are marked true, except for the first occurance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas allows you, with the square bracket notation to [query the dataset](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.query.html). It means that you can request rows or columns based on a criteria that you choose. This is really useful and you are going to use it a lot. It works like that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get all rows where genres is equal to \"Comedy\"\n",
    "\n",
    "# Option 1 (Recommended)\n",
    "print( ... ) \n",
    "\n",
    "# Option 2 (Recommended)\n",
    "print( ... ) \n",
    "\n",
    "# Option 3\n",
    "print( ... ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that our query takes all rows, where genres is equal exactly to the string \"Comedy\", so for example \"Action|Comedy\" is not included. If you want all that **contains** \"Comedy\", then you must use the `str.contains` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get all rows where genres contains \"Comedy\"\n",
    "\n",
    "# Option 1 (Recommended)\n",
    "print( ... ) \n",
    "\n",
    "# Option 2 (Recommended)\n",
    "print( ... ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to know more `str` methods on pandas Series, then check this [documentation](http://pandas.pydata.org/pandas-docs/stable/api.html#string-handling).\n",
    "\n",
    "Now, lets continue and count how many duplicates we have. We will focus only on movie_titles which one or more times in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get all rows from the dataset that are duplicates. (Which are twice or more in the dataset)\n",
    "# Only check movie_title for duplicates.\n",
    "duplicates = ...\n",
    "\n",
    "# Print the head.\n",
    "print('Data:\\n', duplicates.head(10) )\n",
    "\n",
    "# Print the size\n",
    "print('\\nSize:\\n', duplicates.shape[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print title titles only:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print where movie title equals to The Legend of Tarzan\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All right, so we have only 45 duplicates and it looks like those are real duplicates. The question is:\n",
    "\n",
    "**Do we want to keep 2 movies with the same data?**\n",
    "\n",
    "The answer is no. We don't need. We can be sure the duplicates are the 2 same movies. So we can safely remove them.\n",
    "\n",
    "To remove duplicates, we can do it with the `drop_duplicates()` method. ([Documentation](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop_duplicates.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Size of dataset before dropping duplicates: ', len( movie_data ))\n",
    "\n",
    "movie_data = ...\n",
    "\n",
    "print('Size of dataset after dropping duplicates: ', len( movie_data ))\n",
    "\n",
    "# Note that drop_duplicates() return a new DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We can check if there are no duplicate movie titles:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we continue, we should reset the index of the DataFrame. This is unique to pandas, because it is working with an index. At the beginning, our index was [0,1,2,3.....20,21,22,....], but by removing items we can end up with something like [1,2,4,5,....20,25,26,...], which is not very nice.\n",
    "\n",
    "Let's just call this function to reset the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Exploration\n",
    "\n",
    "Our data is clean and we did some preparation. Here, we will try to explore the data in much more details and try to find out interesting informations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Movies per 1. Actor\n",
    "\n",
    "We have a columns 'actor_1_name' and we need to count how many rows are there for the same actor. In other words, in how many movies did each actor play:\n",
    "\n",
    "*Let's make a dictionary, then loop over our 3700 rows and count +1 for each actor we find.*\n",
    "\n",
    "**OR, let's use super pandas features:**\n",
    "\n",
    "In pandas, we can count unique values and have the counts for each one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('There are {} unique first actors.'.format( ... ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print the 10 actors that had most roles played in movies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could very easily plot it with nearly 0 effort:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a very rough and basic plot, but we can read something very interesting from this curve. One one side, many actors are only one first actor, and on the other hand, a few actors are very often first actor.\n",
    "\n",
    "In other words: either you are very successfull and will be main actor in many movies, or you might just do one movie have more difficulties to be main actor again. That would be one interpretation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Best and Worst Movie\n",
    "\n",
    "Now, lets analysis which movie made the most money:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Index of the movie with the maximum gross\n",
    "\n",
    "\n",
    "# The title at that index:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Index of the movie with the minimum gross\n",
    "\n",
    "\n",
    "# ALTERNATIVE: The title at that index:\n",
    "\n",
    "\n",
    "# Note: without .loc, this line doesn't work. Because we select a few columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Index of the movie with the minimum gross\n",
    "\n",
    "\n",
    "# ALTERNATIVE: The title at that index:\n",
    "\n",
    "\n",
    "# Note: without .loc, this line doesn't work. Because we select a few columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, everyboday heard of Avatar. And it seems it was the most successful movie in this dataset. We also found the worst performing movie.\n",
    "\n",
    "### 5.3 Total Gross per Actor\n",
    "\n",
    "Let's analyse and find out which actor has the most chances to make a successful movie. Basically, which actor was able to help generate the most money."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Takes all the first actor names and 'gross' income that the movie made.\n",
    "\n",
    "\n",
    "# Sum all films 'gross' and group by individual actor\n",
    "\n",
    "\n",
    "# Sort the result in descending order (big to small) and keep the 20 first/best elements.\n",
    "\n",
    "\n",
    "# Creates the figure and set the size\n",
    "\n",
    "\n",
    "# Plot the data as a bar plot\n",
    "\n",
    "\n",
    "# Set the title of the plot\n",
    "\n",
    "\n",
    "# Set the label of the y-axis\n",
    "\n",
    "\n",
    "# Set the label of the x-axis\n",
    "\n",
    "\n",
    "# Show the grid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Most Common Genre\n",
    "\n",
    "In ths section, we are going to find out which genre is the most common.\n",
    "\n",
    "So, to work with the genres, we need to split the genres into multiples columns, because right now the data looks like: \"Genre1|Genre2|...\" and that's not a good format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To split the genres by the `|` symbol, we can just use the `str.split()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we are going to get all unique genres from the list of lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we are going to add a new column for each genre. Each movie will have a 0 or 1 for the genres that is covering. To illustrate, we will have somehting like this:\n",
    "\n",
    "| fixed_genres | Action | Comedy | Drama  |\n",
    "|--------|--------|--------|--------|\n",
    "| [Action, Comedy] | 1 | 1 | 0\n",
    "| [Action, Comedy, Drama] | 1 | 1 | 1\n",
    "| [Comedy] | 0 | 1 | 0\n",
    "\n",
    "Adding many columns like that is not an issue. Pandas is really performant and efficient with Big Data.\n",
    "\n",
    "Also, note that, even though this is called pre-processing. We are doing it only now, because before we didn't know or think about this kind of analysis. Remember that it is never too late to do things. And in the worst case, you can even add code where it is missing of course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split the genres by the pipe symbol and add the result as a new column\n",
    "\n",
    "\n",
    "# Loop over unique_genres\n",
    "...\n",
    "    # Add a column, where all values will be a boolean (True/False), that is cast to an int (1/0).\n",
    "    # \"apply\", applies a function on every row of the dataset, in this case:\n",
    "    # For each list in fixed_genre, put a 1 for that row if the genre g is in the list x.\n",
    "    ...\n",
    "\n",
    "# Show the first rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now, if you want to count how many movies have the style Adventure:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We can loop and print all genres:\n",
    "# Additionally, we will store them to plot them also\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert the genre_data into a pandas Series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sort the data from big to small\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creates the figure and set the size\n",
    "\n",
    "\n",
    "# Plot the data as a bar plot\n",
    "\n",
    "\n",
    "# Set the title of the plot\n",
    "\n",
    "\n",
    "# Set the label of the y-axis\n",
    "\n",
    "\n",
    "# Set the label of the x-axis\n",
    "\n",
    "\n",
    "# Show the grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
