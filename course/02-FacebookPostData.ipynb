{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facebook Post Data - Crash Course\n",
    "\n",
    "In this notebook, you are going to analyse your own posts from Facebook. We will explore your data, do some pre-processing on text data and finally find out, for example, which words gave your the most likes or given some text, how many reaction could you expect. The result will be personal to you, so that will be really interesting.\n",
    "\n",
    "\n",
    "So, if you didn't do it yet, go to https://github.com/LuxembourgTechSchool/FacebookPostsToCsv and follow the steps. At the end you should have 2 CSV files named `posts_default.csv` and `reactions_default.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing Libraries\n",
    "\n",
    "As always, we start but importing a few basic libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Panda and give it a shorter name \"pd\"\n",
    "\n",
    "\n",
    "# Import numpy and give it a shorter name \"np\"\n",
    "\n",
    "\n",
    "# Import pyplot from matplotlib and give it a shorter name \"plt\".\n",
    "\n",
    "\n",
    "# Tell Jupyter to to print plots in the cell results (Specific to notebooks only)\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading the Data\n",
    "\n",
    "Next, we load our 2 CSV files.\n",
    "\n",
    "**Important:** Make sure that you set the right path to point to the posts and reactions CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "posts = pd.read_csv('../data/facebook_data/posts_default.csv')\n",
    "reactions = pd.read_csv('../data/facebook_data/reactions_default.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look inside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print the first 10 posts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Size of posts: ', ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print the first few reactions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Size of reactions: ', ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Column Descriptions\n",
    "\n",
    "Starting with Posts, we have the following columns:\n",
    "\n",
    "- **id:** The unique id of the post.\n",
    "- **created_time:** The date/time when the posts has been posted.\n",
    "- **message:** The message of the post.\n",
    "- **story:** The story of the post (e.g. \"John Doe shared a link.\"). This is different than the message.\n",
    "\n",
    "Then for the Reactions we have:\n",
    "\n",
    "- **id:** The unique id of the reaction.\n",
    "- **name:** The name of the person that reacted to your post.\n",
    "- **type:** The type of the reaction (LIKE, LOVE, ANGRY, HAHA,...)\n",
    "- **post:** The id of the post that this reaction is linked to.\n",
    "\n",
    "Note that some posts might have no reactions at all. We will also find out which one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Explore the Data\n",
    "\n",
    "All right, now let's explore the data a little, extract some information and perform some computations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. How many LIKES, LOVES, HAHA, ANGRY, ...\n",
    "\n",
    "Let's start simple by counting and exploring how many types of reaction we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reactions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# here we use numpy where request, which means that it returns all reactions that are equal to \"LIKE\"\n",
    "\n",
    "\n",
    "# as \"reaction_like\" is an array inside the tuple we need to check the lenght of the tuple in index 0\n",
    "len(reaction_like[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now lets see how many of the reactions are \"LOVE\"\n",
    "\n",
    "\n",
    "# as \"reaction_like\" is an array inside the tuple we need to check the lenght of the tuple in index 0\n",
    "len(reaction_like[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now lets see how many of the reactions are \"HAHA\"\n",
    "\n",
    "\n",
    "# as \"reaction_like\" is an array inside the tuple we need to check the lenght of the tuple in index 0\n",
    "len(reaction_like[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now lets see how many of the reactions are \"ANGRY\"\n",
    "\n",
    "\n",
    "# as \"reaction_like\" is an array inside the tuple we need to check the lenght of the tuple in index 0\n",
    "len(reaction_like[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print the value_counts of reaction types\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All right, the numbers are interesting. A plot would be nice too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define variable data with the reaction value counts of types\n",
    "\n",
    "\n",
    "# Plot the data as pie\n",
    "\n",
    "\n",
    "# Set the label on the x-axis\n",
    "\n",
    "\n",
    "# Set the label on the y-axis\n",
    "\n",
    "\n",
    "# Set the title and font size\n",
    "\n",
    "\n",
    "# Show the grid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Who is your Biggest Fan?\n",
    "\n",
    "Let's find out:\n",
    "\n",
    "- Which friend reacted the most to your posts?\n",
    "- Which friend likes your posts the most?\n",
    "- Which friend loves your posts the most?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1. Which friend reacted the most to your posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Easy, let's get the count of rows by name first.\n",
    "reactions_by_name = ...\n",
    "reactions_by_name[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print the result\n",
    "if ...\n",
    "    max_value = ...\n",
    "    max_name = ...\n",
    "    print('{} reacted the most to your posts with {} reactions.'.format(max_name, max_value))\n",
    "else:\n",
    "    print('No one reacted to your posts.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2. Which friend likes your posts the most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "likes_by_name = ...\n",
    "likes_by_name[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print the result\n",
    "if ...\n",
    "    max_value = ...\n",
    "    max_name = ...\n",
    "    print('{} likes your posts {} times.'.format(max_name, max_value))\n",
    "else:\n",
    "    print('No one likes your posts.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3. Which friend loves your posts the most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loves_by_name = ...\n",
    "loves_by_name[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print the result\n",
    "if ...\n",
    "    max_value = ...\n",
    "    max_name = ...\n",
    "    print('{} likes your posts {} times.'.format(max_name, max_value))\n",
    "else:\n",
    "    print('No one loves your posts.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! If you want to find out who reacted the most with ANGRY, HAHA or SAD reactions, you can write the code now or even prepare a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your turn, try a few things out :)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Did you post things multiple times?\n",
    "\n",
    "Let's just see if you repost some of your messages. Note that this is not really a duplicate that you need to remove, it is just a message that you posted 2+ times over the years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Number of reposts: {}'.format( ... ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's see a few of those messages:\n",
    "\n",
    "query = ...\n",
    "posts[ query ][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Pre-Processing\n",
    "\n",
    "## 4.1. Duplicates\n",
    "\n",
    "What are duplicates here?\n",
    "\n",
    "For posts, it would be 2 posts at the same time, with the same message and same ID. From how we get the data, we know it is not really possible. \n",
    "\n",
    "Then, removing all posts where the message or story is the same is not a good idea, because, let's say you posted \"Happy New Year\" every year! That's the same message string but on different dates. So for us, we are going to keep everything.\n",
    "\n",
    "For scientific reasons, we are still going to print the number of duplicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# How many 'full' duplicated rows in posts?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# How many 'full' duplicated rows in reactions?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Missing Values\n",
    "\n",
    "The same is valid here. Because of the method (Facebook API + Script) that we have used to get the data, we know there are no missing values that would not allow us to process a row.\n",
    "\n",
    "The only detail to remember is that `message` or `story` can be `Nan` (Empty in pandas/numpy). But this is not a big deal, you will see later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4.3. Format Dates\n",
    "\n",
    "Each post has a datetime column. Since it is a string we are going to convert it into a real Python datetime object and then we are going to extract a few date components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First, check the format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas has a function for working with date/time data. It is explained [here](http://pandas.pydata.org/pandas-docs/version/0.19.1/generated/pandas.to_datetime.html).\n",
    "\n",
    "It allows us to convert a string to a real `datetime` object representing the date and time. All we have to do is call the method and give it the format of the date/time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Month/Day/Year Hours:Minutes/Seconds\n",
    "datetime_format = '%Y/%m/%dT%H:%M:%S'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we will do, is just override the 'Date/Time' columns with our new data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check again. Note that the dtype has changed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now get the desired components and store it in new columns. To create a new column, you can just define it the same way as you would define a key in a dictionary.\n",
    "\n",
    "This is the power of pandas at work. We don't need to loop. Pandas handle everything for us and fills up every row for our new columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# checking what do we have now in our database\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now we are readz to plot some intersting things."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Advanced Exploration\n",
    "\n",
    "Let's go ahead and plot the posts per hour and find out what are the times you post the most things.\n",
    "\n",
    "Then, we are going to see what day of the week you are the most active too.\n",
    "\n",
    "And at last, we are going to find out, what words can give you the most reactions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Posts per Hour\n",
    "\n",
    "To create the plot, we are going to learn about pivot tables. We could achieve something similar with the value_counts() but in this case, it is cleaner with this method. You can read up [here](http://pbpython.com/pandas-pivot-table-explained.html) a really nice introduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a pivot table, taking all unique HourOfDay values, and counting the number of messages.\n",
    "# The aggregate function is count.\n",
    "\n",
    "\n",
    "# See the result.\n",
    "print(post_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's plot the things\n",
    "\n",
    "\n",
    "\n",
    "# Set the label on the x-axis\n",
    "\n",
    "\n",
    "# Set the label on the y-axis\n",
    "\n",
    "\n",
    "# Set the title and font size\n",
    "\n",
    "\n",
    "# Show the grid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Posts by Day of Week\n",
    "\n",
    "We do the same for the day of the week, the steps are the same, first we make the pivot table, then we plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1. Create the pivot table.\n",
    "\n",
    "\n",
    "# Note that this time, it is order by DayOfWeekNum, which is prefered for us.\n",
    "print(post_weekdays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's plot the data at a bar chart. Give the plot a width of 10 and height of 6. Make the bars 50% transparent.\n",
    "\n",
    "\n",
    "# Set the label on the x-axis\n",
    "\n",
    "\n",
    "# Set the label on the y-axis\n",
    "\n",
    "\n",
    "# Set the title and font size\n",
    "\n",
    "\n",
    "# Show the grid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5.3. Words That Give The Most Reactions\n",
    "\n",
    "Now, we are going to find out and maybe predict what words you should be using in your posts in order to generate the most number of reactions. For this we need to do a few things:\n",
    "\n",
    "1. Posts and Reactions are in 2 seperate files / databases, we need to merge them in some way.\n",
    "2. Message or Story are long texts, so we need to process the text and, for example, remove all special characters and split by words.\n",
    "\n",
    "In order words, the goal is to have, for each row, the list of words and the number of reactions, then we could find a way to get a ratio of number of reaction per word for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.1. Add Number of Reactions to Posts Data\n",
    "\n",
    "Let's start by counting the number of reactions for each posts and store that value in a new columns, we want to build something like this:\n",
    "\n",
    "|id|message|n_reactions|n_like|n_haha|...|\n",
    "|----|----|----|----|----|----|\n",
    "|1|M1|10|5|5|...|\n",
    "|2|M2|4|0|2|...|\n",
    "|3|M3|30|29|2|...|\n",
    "|4|M4|120|67|29|...|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First, we can create a pivot table where we index the post and type and use count as aggregate function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The result is exactly what we want\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All right, we are nearly done with this pre-processing. Now we are going to be a little creative.\n",
    "\n",
    "We will create the new columns `n_reactions`, `n_like`, `n_haha` and `n_angry` by using the `apply()` function.\n",
    "So, we are going to define a function that will get the reaction from the `reaction_pt` pivot table based on the post_id. If the post has no reactions, meaning, it is not in the table, then we just add 0.\n",
    "\n",
    "**Important:** This is very little code but it is doing a loooot, so take the time to really understand every parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Example: This is how you get the item by the index.\n",
    "print('Item at index 0:',  ... )\n",
    "print('Reaction LIKE for item at index 0:',  ... )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We define our function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We call our function in the apply using a lambda expression, x is the post_id\n",
    "\n",
    "print('Processing n_reactions...')\n",
    "posts['n_reactions'] = posts['id'].apply( lambda x : get_reaction(x, 'All') )\n",
    "\n",
    "print('Processing n_like...')\n",
    "posts['n_like'] = posts['id'].apply( lambda x : get_reaction(x, 'LIKE') )\n",
    "\n",
    "print('Processing n_love...')\n",
    "posts['n_love'] = posts['id'].apply( lambda x : get_reaction(x, 'LOVE') )\n",
    "\n",
    "print('Processing n_haha...')\n",
    "posts['n_haha'] = posts['id'].apply( lambda x : get_reaction(x, 'HAHA') )\n",
    "\n",
    "print('Processing n_sad...')\n",
    "posts['n_sad'] = posts['id'].apply( lambda x : get_reaction(x, 'SAD') )\n",
    "\n",
    "print('Processing n_wow...') # TODO: WOW\n",
    "posts['n_wow'] = ...\n",
    "\n",
    "print('Processing n_angry...') # TODO: ANGRY\n",
    "posts['n_angry'] = ...\n",
    "\n",
    "print('All Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print the first 10 posts\n",
    "posts[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Ready for the next step.\n",
    "\n",
    "### 5.3.2. Text-Processing on Message Column\n",
    "\n",
    "All right, to be able to work with the message column, which is just text, we must process it. In simple Big Data analytics, this often means that we start by splitting the text into a list of words, getting rid of everything we don't need such as special symbols and stop words.\n",
    "\n",
    "Why? So that we are able to map specific words to, for example, the number of likes. \n",
    "\n",
    "Does talking about your dog or cat gives you more like than complaining about Mondays? \n",
    "\n",
    "Then, based on a new message, how many likes could you expect? This is the kind of analysis that we can do, once the text data is transformed.\n",
    "\n",
    "I recommend that you also read [this tutorial](https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-1-for-beginners-bag-of-words). It's a beginner introduction to text analysis techniques. We are going to use certain aspect explained there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Looking at messages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "From the exploration we know that sometimes the message is `NaN` when story is not. For us, we are going to replace all `NaN` with en empty string `\"\"`. What is in the story we are going to ignore it for now, feel free to work on that part for yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Replace all NaN with empty string \"\"\n",
    "# fillna() return a DataFrame, where all the NaN values has been replaced with another value given\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to demonstrate each step of the process and then use a function that performs each step for every row.\n",
    "\n",
    "**Steps:**\n",
    "\n",
    "1. Remove certain special symbols.\n",
    "1. Lowercase everthing.\n",
    "1. Split by words.\n",
    "1. Remove english stop words (a, an, is, of, ...)\n",
    "1. Save the result as a simplified paragraph \"word1 word2 word3 ...\"\n",
    "\n",
    "Let's get to work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We will just use the first message:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1. Remove certain special symbols and replace by a space.\n",
    "import re\n",
    "\n",
    "symbols = \"[.,\\[\\]{}|\\`~\\'\\\"*&^%$@!?+>\\-\\_]\"\n",
    "\n",
    "result = ...\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 2. Lowercase everthing.\n",
    "result = ...\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 3. Split by words\n",
    "result = ...\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# English, German and French stopwords.\n",
    "english_stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', 'couldn', 'didn', 'doesn', 'hadn', 'hasn', 'haven', 'isn', 'ma', 'mightn', 'mustn', 'needn', 'shan', 'shouldn', 'wasn', 'weren', 'won', 'wouldn']\n",
    "german_stopwords = ['aber', 'alle', 'allem', 'allen', 'aller', 'alles', 'als', 'also', 'am', 'an', 'ander', 'andere', 'anderem', 'anderen', 'anderer', 'anderes', 'anderm', 'andern', 'anderr', 'anders', 'auch', 'auf', 'aus', 'bei', 'bin', 'bis', 'bist', 'da', 'damit', 'dann', 'der', 'den', 'des', 'dem', 'die', 'das', 'daß', 'derselbe', 'derselben', 'denselben', 'desselben', 'demselben', 'dieselbe', 'dieselben', 'dasselbe', 'dazu', 'dein', 'deine', 'deinem', 'deinen', 'deiner', 'deines', 'denn', 'derer', 'dessen', 'dich', 'dir', 'du', 'dies', 'diese', 'diesem', 'diesen', 'dieser', 'dieses', 'doch', 'dort', 'durch', 'ein', 'eine', 'einem', 'einen', 'einer', 'eines', 'einig', 'einige', 'einigem', 'einigen', 'einiger', 'einiges', 'einmal', 'er', 'ihn', 'ihm', 'es', 'etwas', 'euer', 'eure', 'eurem', 'euren', 'eurer', 'eures', 'für', 'gegen', 'gewesen', 'hab', 'habe', 'haben', 'hat', 'hatte', 'hatten', 'hier', 'hin', 'hinter', 'ich', 'mich', 'mir', 'ihr', 'ihre', 'ihrem', 'ihren', 'ihrer', 'ihres', 'euch', 'im', 'in', 'indem', 'ins', 'ist', 'jede', 'jedem', 'jeden', 'jeder', 'jedes', 'jene', 'jenem', 'jenen', 'jener', 'jenes', 'jetzt', 'kann', 'kein', 'keine', 'keinem', 'keinen', 'keiner', 'keines', 'können', 'könnte', 'machen', 'man', 'manche', 'manchem', 'manchen', 'mancher', 'manches', 'mein', 'meine', 'meinem', 'meinen', 'meiner', 'meines', 'mit', 'muss', 'musste', 'nach', 'nicht', 'nichts', 'noch', 'nun', 'nur', 'ob', 'oder', 'ohne', 'sehr', 'sein', 'seine', 'seinem', 'seinen', 'seiner', 'seines', 'selbst', 'sich', 'sie', 'ihnen', 'sind', 'so', 'solche', 'solchem', 'solchen', 'solcher', 'solches', 'soll', 'sollte', 'sondern', 'sonst', 'über', 'um', 'und', 'uns', 'unsere', 'unserem', 'unseren', 'unser', 'unseres', 'unter', 'viel', 'vom', 'von', 'vor', 'während', 'war', 'waren', 'warst', 'was', 'weg', 'weil', 'weiter', 'welche', 'welchem', 'welchen', 'welcher', 'welches', 'wenn', 'werde', 'werden', 'wie', 'wieder', 'will', 'wir', 'wird', 'wirst', 'wo', 'wollen', 'wollte', 'würde', 'würden', 'zu', 'zum', 'zur', 'zwar', 'zwischen']\n",
    "french_stopwords = ['au', 'aux', 'avec', 'ce', 'ces', 'dans', 'de', 'des', 'du', 'elle', 'en', 'et', 'eux', 'il', 'je', 'la', 'le', 'leur', 'lui', 'ma', 'mais', 'me', 'même', 'mes', 'moi', 'mon', 'ne', 'nos', 'notre', 'nous', 'on', 'ou', 'par', 'pas', 'pour', 'qu', 'que', 'qui', 'sa', 'se', 'ses', 'son', 'sur', 'ta', 'te', 'tes', 'toi', 'ton', 'tu', 'un', 'une', 'vos', 'votre', 'vous', 'c', 'd', 'j', 'l', 'à', 'm', 'n', 's', 't', 'y', 'été', 'étée', 'étées', 'étés', 'étant', 'étante', 'étants', 'étantes', 'suis', 'es', 'est', 'sommes', 'êtes', 'sont', 'serai', 'seras', 'sera', 'serons', 'serez', 'seront', 'serais', 'serait', 'serions', 'seriez', 'seraient', 'étais', 'était', 'étions', 'étiez', 'étaient', 'fus', 'fut', 'fûmes', 'fûtes', 'furent', 'sois', 'soit', 'soyons', 'soyez', 'soient', 'fusse', 'fusses', 'fût', 'fussions', 'fussiez', 'fussent', 'ayant', 'ayante', 'ayantes', 'ayants', 'eu', 'eue', 'eues', 'eus', 'ai', 'as', 'avons', 'avez', 'ont', 'aurai', 'auras', 'aura', 'aurons', 'aurez', 'auront', 'aurais', 'aurait', 'aurions', 'auriez', 'auraient', 'avais', 'avait', 'avions', 'aviez', 'avaient', 'eut', 'eûmes', 'eûtes', 'eurent', 'aie', 'aies', 'ait', 'ayons', 'ayez', 'aient', 'eusse', 'eusses', 'eût', 'eussions', 'eussiez', 'eussent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import the predefined stopwords\n",
    "\n",
    "print('\\nEnglish Stop Words:')\n",
    "print( english_stopwords )\n",
    "\n",
    "print('\\German Stop Words:')\n",
    "print( german_stopwords )\n",
    "\n",
    "print('\\nFrench Stop Words:')\n",
    "print( french_stopwords )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 4. Remove all elements in the list that are english stopwords\n",
    "result = ...\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Note that we make use of many built-in libraries inside Anaconda and that for text processing those techniques can easily be applied to any text that you have. So keep those methods close to you so that you can copy and paste the functions you need.\n",
    "\n",
    "Now let's make a function that will do all those steps and then apply it to every row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def process_text(raw_text):\n",
    "    # 1. Remove certain special symbols and replace by a space.\n",
    "    text = re.sub(\"[.,\\[\\]{}|\\`~\\'\\\"“”’*&^%$@!?+>\\-\\_]\", \" \", raw_text)\n",
    "\n",
    "    # 2. Lowercase\n",
    "    ...\n",
    "    \n",
    "    # 3. Split by words\n",
    "    ...\n",
    "    \n",
    "    # 4. Remove English stop words\n",
    "    \n",
    "    # Sets are much faster than lists in Python for membership comparisons\n",
    "    stops = set(english_stopwords)\n",
    "    \n",
    "    ...\n",
    "    \n",
    "    # 5. Return the words concantenated with eachother\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's try the method for multiple inputs:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now we can apply it to every row and store it in a new column\n",
    "posts['processed_message'] = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# And Tadaaaaa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now, let's loop over all rows, take each word of the `processed_message` column and create a new dictionary where each word is a key and the value is the sum of the number of reactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define empty dictionary\n",
    "\n",
    "\n",
    "# Define function that will process one processed_message\n",
    "def handle_processed_message(message, n_reactions):\n",
    "    # Split by space\n",
    "    words = ...\n",
    "    \n",
    "    # Loop over words and add n_reactions to the dictionary\n",
    "    ...\n",
    "        # If the word is already know, add\n",
    "        ...\n",
    "            \n",
    "print('Starting...')\n",
    "# Call the method for each row:\n",
    "posts.apply(lambda row : ..., axis=1)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# See the dictionary\n",
    "word_reaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert to Serie\n",
    "word_reaction = ...\n",
    "\n",
    "# Sort from Big to Small\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Take a look at the 10 best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Take a look at the 10 worst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the 100 best words\n",
    "\n",
    "# Let's plot the data at a bar chart.\n",
    "# Make sure that the plot is big enough and DO NOT plot everything, just select a subset, because otherwise it\n",
    "# will be unreadable\n",
    "\n",
    "\n",
    "# Set the label on the x-axis\n",
    "\n",
    "\n",
    "# Set the label on the y-axis\n",
    "\n",
    "\n",
    "# Set the title and font size\n",
    "\n",
    "\n",
    "# Show the grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the 100 worst words\n",
    "\n",
    "# Let's plot the data at a bar chart.\n",
    "# Make sure that the plot is big enough and DO NOT plot everything, just select a subset, because otherwise it\n",
    "# will be unreadable\n",
    "\n",
    "\n",
    "# Set the label on the x-axis\n",
    "\n",
    "\n",
    "# Set the label on the y-axis\n",
    "\n",
    "\n",
    "# Set the title and font size\n",
    "\n",
    "\n",
    "# Show the grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
