{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Technique 1 - Regression\n",
    "\n",
    "# 1. Predict a value - Predict price of a house\n",
    "\n",
    "This notebook will demonstrate how to use basic scikit functionalities to predict a value.\n",
    "As an example, we are going to use a dataset from kaggle competition that is very interesting to use for basic and advanced regression techniques. The dataset contains housing data from the city Ames, Iowa (USA).\n",
    "\n",
    "- The dataset comes with 2 CSV, a training CSV and a test CSV.\n",
    "- The training CSV contains features of houses with their price and the goal is to create a model and predict the prices of the test CSV.\n",
    "- The predicted prices for the tests could be submitted to kaggle to participate to the competition.\n",
    "\n",
    "For us, we are just going to work on the training data and see if we can make a nice and correct model.\n",
    "\n",
    "This notebook encapsulates all important code into functions that are **easy to reuse in other notebooks or in your project**.\n",
    "\n",
    "#### Data:\n",
    "\n",
    "You can find the data in your OneDrive under `house_data/`\n",
    "\n",
    "#### Links:\n",
    "\n",
    "[Kaggle Competition](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/kernels)\n",
    "\n",
    "[Explanations to the Dataset columns](https://ww2.amstat.org/publications/jse/v19n3/decock/DataDocumentation.txt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Starting by importing our beloved libraries: pandas, numpy, matplotlib.pyplot\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "house_train = pd.read_csv('../data/house_data/train.csv')\n",
    "house_test = pd.read_csv('../data/house_data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# See the training data\n",
    "house_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# See the test data\n",
    "house_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Explore a little"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Notice that there are a lot of columns.\n",
    "# Let's see how much.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Slice / Split the data into training and validation\n",
    "\n",
    "Now, we are going to split our training data in 2 datasets, train and validation.\n",
    "\n",
    "We learned in the course why it is important to have a training and validation set.\n",
    "\n",
    "Just remember that when you use a machine learning algorithm, you basically create a model that needs to be trained on your data.\n",
    "Essentially, you preprocess your data, give it to the algorithm and it will learn something.\n",
    "In this case, we will give some columns of our housing data plus the prices from the training data.\n",
    "\n",
    "The algorithm will try to find relations bewteen, for example, the number of bedrooms, the size of the house and the price of the house.\n",
    "\n",
    "Then, to test your algorithm, you should ask him to predict the price of a house that is NOT part of the training data.\n",
    "That way, you can effectively test if your model is great or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split the data, 70% for training, 30% for validation\n",
    "# If there is any red message, it is just a \"DeprecationWarning\", meaning that some function\n",
    "# will be changed in the next version of the library\n",
    "...\n",
    "\n",
    "# train_test_split returns 2 values\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Size of train      : {}'.format(house_x_train.shape[0]))\n",
    "print('Size of validation : {}'.format(house_x_validation.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has been split. Now we are going to extract the column that we want to predict, which is `SalePrice`.\n",
    "\n",
    "The reason we do that is because of how scikit algorithms work. Typically they ask to get the features and the target separatly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract the SalePrice as target y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Scale the values\n",
    "\n",
    "Because we are doing basic regression, we will only select a few columns that contains integer or float values.\n",
    "We will need to scale those columns, because of how regression algorithm works.\n",
    "\n",
    "Essentially, most regression algorithm are just a linear (`y = c * x + i`) or polynomial (`y = c * x + c * x^2 + ... +  i`) formula. \n",
    "\n",
    "So if you try to use, for example, the number of bedrooms and the price in the same equation you might have numerical issues, because bedrooms are in the range of 1 to 5 most of the time and prices can go into the millions.\n",
    "For this reason, we scale or normalize the values.\n",
    "\n",
    "Again, this is just an overview to show what is possible using scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select a few features only\n",
    "columns = ['MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', '1stFlrSF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NOTE: Ingore all Red Big Warnings, it is not important and doesn't break anything.\n",
    "\n",
    "\n",
    "\n",
    "# Create two different Scaler and fit them with all training columns, respectively all training prices data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Creating, Training & Measuring the Model\n",
    "\n",
    "Next, we are going to create multiple Machine Learning models, train them, test their performance and see what works best for us.\n",
    "\n",
    "We provide multiple functions that will make it easier for you to get started.\n",
    "\n",
    "**Performance:**\n",
    "\n",
    "We will use the [coefficient of determination](https://en.wikipedia.org/wiki/Coefficient_of_determination) to measure the model's performance.\n",
    "This value is between 0 and 1, 1 being the best.\n",
    "\n",
    "We will see that we can use mutliple algorithms to do regression jobs. We have to measure and see what model suits best for us.\n",
    "Note that we only cover the basics, each alorithm has a lot of specific parameters and features that can be tuned to improve the performance.\n",
    "\n",
    "The next few cells will define a few functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import *\n",
    "\n",
    "def train_and_evaluation(model, x_train, y_train):\n",
    "    ''' Trains and evaluation the performance of a Regression Model.\n",
    "    \n",
    "    Returns the scores array.\n",
    "    '''\n",
    "    ...\n",
    "    \n",
    "    print('Coefficient of determination on training set: {}'.format( ... ) )\n",
    "          \n",
    "    # create a k-fold cross validation iterator of k=5 folds\n",
    "    cv = KFold(x_train.shape[0], 5, shuffle=True, random_state=33)\n",
    "    \n",
    "    scores = cross_val_score(model, x_train, y_train, cv=cv)\n",
    "    print('Average coefficient of determination using 5-fold crossvalidation:', np.mean(scores))\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_model(model, x, y, label='Model'):\n",
    "    ''' Makes a simple plot of the predictions of a model.\n",
    "    '''\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Simple Linear Regression\n",
    "\n",
    "Let's start with a simple linear regression model.\n",
    "\n",
    "[Documentation](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the Model\n",
    "\n",
    "\n",
    "# Train and evaluate\n",
    "\n",
    "\n",
    "# Plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the Model\n",
    "\n",
    "\n",
    "# Train and evaluate\n",
    "\n",
    "\n",
    "# Plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Support Vector Machines (SVM) \n",
    "\n",
    "This is another algorithm that can be used to perform regression.\n",
    "\n",
    "[Documentation](http://scikit-learn.org/stable/modules/svm.html#regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the Model\n",
    "\n",
    "\n",
    "# Train and evaluate\n",
    "\n",
    "\n",
    "# Plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the Model\n",
    "\n",
    "\n",
    "# Train and evaluate\n",
    "\n",
    "\n",
    "# Plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the Model\n",
    "\n",
    "\n",
    "# Train and evaluate\n",
    "\n",
    "\n",
    "# Plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 7.3 Random Forest\n",
    "\n",
    "This is yet another algorithm, but this time based on Decisions Trees.\n",
    "\n",
    "In this example it is intersting to see that we can find out what features / columns **are most important** to the algorithm for predicting the prices.\n",
    "\n",
    "[Documentation](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesRegressor.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the Model\n",
    "\n",
    "\n",
    "# Train and evaluate\n",
    "\n",
    "\n",
    "# Plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Here we print the importance of the features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that `OverallQual` weights in at 60% for deciding the price of the house.\n",
    "Also note that we should definitely use more features, but here let's keep it simple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4 AdaBoost\n",
    "\n",
    "And this is the final algorithm that we will try.\n",
    "\n",
    "[Documentation](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html#sklearn.ensemble.AdaBoostRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the Model\n",
    "\n",
    "\n",
    "# Train and evaluate\n",
    "\n",
    "\n",
    "# Plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Model Evaluation\n",
    "\n",
    "Let's finish by making a small method that will evaluate our model.\n",
    "\n",
    "Before, we trained and evaluate our model on training data.\n",
    "Now we will measure the model on the validation data and get our final coefficient of determination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Linear': model_linear,\n",
    "    'Linear l2': model_linear_l2,\n",
    "    'SVM-Linear': model_svr,\n",
    "    'SVM-Poly': model_svr_poly,\n",
    "    'SVM-RBF': model_svr_rbf,\n",
    "    'Random Forest': model_rf,\n",
    "    'Adaboost': model_ada\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Predict Values\n",
    "\n",
    "Finally, ones you are happy with a model, you can predict values of new houses!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction = ...\n",
    "print('Predictions (scaled): \\n{}'.format(prediction)) # Those are the predictions scaled\n",
    "\n",
    "# We can inverse transform the predictions to get the real dollar price\n",
    "prediction = ...\n",
    "print('\\nPredictions ($): \\n{}'.format(prediction))\n",
    "\n",
    "# We can add the predictions as a column to our test data and then print.\n",
    "\n",
    "\n",
    "# Print the house_test, note that many features are scalled.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Validation Curves: Plot scores to evaluate models (OPTIONAL)\n",
    "\n",
    "This next section is more advanced.\n",
    "It consists of plotting different things such as the scores and learning curves in order to visualize and evaluate our model.\n",
    "\n",
    "[Documentation](http://scikit-learn.org/stable/modules/learning_curve.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and training learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 3-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - An object to be used as a cross-validation generator.\n",
    "          - An iterable yielding train/test splits.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : integer, optional\n",
    "        Number of jobs to run in parallel (default 1).\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the Model that uses SVM with RBF\n",
    "\n",
    "cv = KFold(house_x_train[columns].shape[0], 5, shuffle=True, random_state=33)\n",
    "plot_learning_curve(model_rf, 'SVM RBF', house_x_train[columns], house_y_train, cv=cv, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_learning_curve(model_svr_rbf, 'SVM RBF', house_x_train[columns], house_y_train, cv=cv, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
