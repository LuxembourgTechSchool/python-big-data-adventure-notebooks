{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Technique 2 - Classification\n",
    "\n",
    "# 1. Document classification - Spam or Not Spam Emails \n",
    "\n",
    "This notebook will demonstrate text classification based on basic scikit functionalities. \n",
    "Document classification can be applied in many different applications such as filtering spam, detecting languages, classifying genres, and much more.\n",
    "\n",
    "In this example we will build a simple spam filter which will classify texts of emails into two classes: spam, or not spam (a.k.a [ham](https://en.wiktionary.org/wiki/ham_e-mail)). \n",
    "\n",
    "The goal will be to build a simple spam filter. While the filters in services like Gmail are very advanced, the model we will have by the end of this lesson is effective, and quite accurate.\n",
    "\n",
    "#### Data:\n",
    "\n",
    "The data has been already fetched and transformed for you. You just have to download the CSV file from your OneDrive in `/email_data/emails.csv`.\n",
    "\n",
    "FYI: the original data comes from the following websites:\n",
    "\n",
    "- [Enron-Spam](http://www.aueb.gr/users/ion/data/enron-spam/)\n",
    "- [SpamAssassin](https://spamassassin.apache.org/publiccorpus/)\n",
    "\n",
    "#### Links:\n",
    "\n",
    "- [Tutorial this lesson is based on](http://zacstewart.com/2015/04/28/document-classification-with-scikit-learn.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Starting by importing our beloved libraries: pandas, numpy, matplotlib.pyplot\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Load the Data\n",
    "\n",
    "We are now going to load the `email.csv`, which contains all email data. This dataset is already labelled. This means that each email has a label `spam` or `ham`. \n",
    "\n",
    "*(BTW, ham is a relatively new synonym for \"not Spam\")*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "\n",
    "# The CSV is quite large, so we might need to extend the limit the system.\n",
    "#csv.field_size_limit(sys.maxsize)\n",
    "csv.field_size_limit(500 * 1024 * 1024)\n",
    "\n",
    "email_data = pd.read_csv('../data/classification_data/emails.csv', sep=None, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# See the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# length of the data\n",
    "print('Number of Emails: {}'.format( ... ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Count the number of spam email and the number of ham emails\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, we have quite a 50/50 distribution of spam and not spam emails. \n",
    "\n",
    "When doing classification with labelled data, it is best to have a training dataset where each class is represented in an equal manner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Check some Emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Random number between 0 and #emails\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there is a lot of formatting code ([HTML](https://www.w3schools.com/html/)).\n",
    "\n",
    "We might need some serious **pre-processing to remove all those things**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Length of Emails\n",
    "\n",
    "Let's, for fun, also check the length of the emails.\n",
    "\n",
    "We are going to add the length of the raw email data as a column and then compute some statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First, we can try to compute the length for each email using a lambda expression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now, we can add that to a new column\n",
    "\n",
    "\n",
    "# Then print the first 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now make use of an useful function that we did not see yet, and that is the [describe()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html) function.\n",
    "\n",
    "Let's just see it in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First we group our data by the `class`, take the column length (must be numerical)\n",
    "# and then we compute some statistiques.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Pre-Processing\n",
    "\n",
    "We have seen that the data is a little dirty and contains a lot of HTML. Let's clean this up! What? Does it look like real garbage to you? It is not pretty, that is sure, but fortunatly for us, there some amazing libraries out there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# BEFORE\n",
    "email_data['text'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# AFTER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, looks much better!\n",
    "\n",
    "Let's use this and add a **new column** for our DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's remove all \\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check the number of duplicates and/or empty\n",
    "def check_data():\n",
    "    print('Number of duplicates: {}'.format( ... ))\n",
    "    print('Number of empty: {}'.format( ... ))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove all empty rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 6. Slice / Split the data into training and validation\n",
    "\n",
    "Now we are going to split the data in order to train and evaluate the model. \n",
    "\n",
    "We will perform a 90%/10% for training and testing. The training will be used to train the model, using a technique called cross validation. \n",
    "\n",
    "In `sklearn` there is a class called [KFold](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) for this purpose. Cross validation consist of splitting the data in k parts / folds and each part is then used once as a validation data while the k-1 remaining parts are used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Size of Training : {}'.format( len(email_train) ))\n",
    "print('Size of Testing  : {}'.format( len(email_test) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Feature Extraction\n",
    "\n",
    "Now come sthe time to extract data or knowledge from the processed text. A machine learning algorithm needs more than text to work. This is why we need to extract features from the text and for example, generate a count by word. An algorithm basically needs numbers, especially in machine learning.\n",
    "\n",
    "We will start by using a basic `CountVectorizer` to count each word.\n",
    "\n",
    "**Links:**\n",
    "\n",
    "- [CountVectorizer Documentation](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import CountVectorizer\n",
    "\n",
    "\n",
    "# Create a new CountVectorizer instance\n",
    "\n",
    "\n",
    "# fit_transform learns the vocabulary dictionary of the dataframe and extracts word counts as features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check the size of the matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matrix resulting from the `transform` is a `n*m` matrix , where:\n",
    "\n",
    "- `n` is the number of documents (emails)\n",
    "- `m` is the number of words\n",
    "\n",
    "The matrix looks something like this:\n",
    "\n",
    "|Document |word1|word2|word3|...|\n",
    "|---|---|---|---|---|\n",
    "|0        | 4| 8| 0| ... |\n",
    "|1        | 0| 23| 5| ... |\n",
    "|2        | 12| 3| 14| ... |\n",
    "|...        | ...| ...| ...| ... |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the vocabulary\n",
    "\n",
    "\n",
    "# Sum up the counts of each vocabulary word\n",
    "\n",
    "\n",
    "# For each, print the vocabulary word and the number of times it \n",
    "# appears in the training set\n",
    "for tag, count in sorted(zip(vocabulary, dist), key=lambda pair: pair[1], reverse=True):\n",
    "    print(count, tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Create the Model - Classify Emails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 Naive Bayes Classifier\n",
    "\n",
    "The first classification algorithm will be one based on Naive Bayes. \n",
    "\n",
    "**Links:**\n",
    "\n",
    "- [Documentation MultinomialNB](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html)\n",
    "\n",
    "- [Advanced Explanations 1](http://www.statsoft.com/textbook/naive-bayes-classifier)\n",
    "- [Advanced Explanations 2](http://software.ucv.ro/~cmihaescu/ro/teaching/AIR/docs/Lab4-NaiveBayes.pdf)\n",
    "- [Advanced Explanations 3](http://ix.cs.uoregon.edu/~dou/research/papers/icdm11_fw.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import sklean implementaton of Naive Bayes\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now lets check few examples\n",
    "\n",
    "examples = [\n",
    "    \"I'm going to attend the Linux users group tomorrow.\", \n",
    "    'Free Viagra call today!', \n",
    "    'Python online classes'\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Measure Performance\n",
    "\n",
    "All right, we have a model, and now we should measure its performance and find out if the model is accurate or not.\n",
    "\n",
    "We will define a few method to help us print the accuracy of our model(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import *\n",
    "\n",
    "def cross_validate(classifier, x, true_labels, k=5):\n",
    "    # Create our cross validator with 5-fold\n",
    "    cv = KFold(true_labels.shape[0], k, shuffle=True, random_state=42)\n",
    "\n",
    "    # Compute the scores\n",
    "    scores = cross_val_score(classifier, x, true_labels, cv=cv)\n",
    "    \n",
    "    # Print the results\n",
    "    print(\"Accuracy: {:.2f} (+/- {:.2f}) and {} folds\".format(scores.mean(), scores.std() * 2, k))\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model is trained on training data. We have now to take the test data and find out the real accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the CountVectorizer for the test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predict our test classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Measure Accuracy of Test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1 Classification Report, Confusion Matrix, ...\n",
    "\n",
    "In this section, we are going to see additional ways to evaluate our classifier. Those evaluation only work with labelled data, because the predictions are evaluated based on the true values from your data.\n",
    "\n",
    "**Links:**\n",
    "\n",
    "- [Classification Report Documentation](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)\n",
    "- [Confusion Matrix Documentation](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)\n",
    "- [Confusion Matrix, Precison and Recall Explained](http://docs.statwing.com/the-confusion-matrix-and-the-precision-recall-tradeoff/)\n",
    "- [Confusion Matrix Terminology](http://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print the classification report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(true_labels, predictions, classes):\n",
    "    # Create Confusion Matrix\n",
    "    cm = ...\n",
    "\n",
    "    print('Confusion Matrix:')\n",
    "    print(cm)\n",
    "    \n",
    "    # Plot    \n",
    "\n",
    "    plt.matshow(cm, cmap=plt.cm.binary, interpolation='nearest')\n",
    "    \n",
    "    plt.xlabel('predicted class')\n",
    "    plt.ylabel('expected class')\n",
    "    \n",
    "    tick_marks = np.arange( len(classes) )\n",
    "    plt.xticks(tick_marks, classes)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion Matrix Explained:**\n",
    "\n",
    "- There are 2 possible predicted classes: *spam* or *ham*.\n",
    "- In total we have `1443 + 1418 +33 + 136 = 3030` predictions.\n",
    "- Out of 3030 predictions, 1443 have been predicted as *ham* and 1476 as *spam*\n",
    "- Actually `136 + 1418 = 1554` are really *spam* and `1443 + 33 = 1476` are really *ham*\n",
    "\n",
    "**Terms:**\n",
    "\n",
    "Let's go into more detail and define the correct terms:\n",
    "\n",
    "- True Positives (TP): We predicted *ham* (yes, it is safe), and the emails are *ham*.\n",
    "- True Negatives (TN): We predicted *spam* (no, it is not safe), and the emails are *spam*.\n",
    "- False Positives (FP): We predicted *ham* (yes), but the emails are *spam*.\n",
    "- False Negatives (FN): We predicted *spam* (no), but the emails are *ham*.\n",
    "\n",
    "Those terms map to the confusion matrix above like this:\n",
    "\n",
    "![Image 1](http://rasbt.github.io/mlxtend/user_guide/evaluate/confusion_matrix_files/confusion_matrix_1.png)\n",
    "\n",
    "**Accuracy:**\n",
    "\n",
    "Overall, how often is the classifier correct?\n",
    "\n",
    "    ( TP + TN ) / total = ( 1443 + 1418 ) / 3030 = 0.94\n",
    "\n",
    "**Precision:**\n",
    "\n",
    "When it predicts *ham* (yes), how often is it correct?\n",
    "\n",
    "    TP / ( TP + FP ) = 1443 / (1443 + 136) = 0.91\n",
    "\n",
    "**Recall:**\n",
    "\n",
    "Recall is also called *Sensitivity* or *True Positive Rate*.\n",
    "It describes: When it's actually *ham* (yes), how often does it predict *ham* (yes)?\n",
    "\n",
    "    TP / ( TP + FN ) = 1443 / (1443 + 33) = 0.98 (rounded up)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Accuracy                        :', ...)\n",
    "print('Accuracy from sklearn function  :', accuracy_score(email_test['class'], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Precision:', ... )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Recall:', ... )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
